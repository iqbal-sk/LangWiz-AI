{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:35:11.186050Z",
     "start_time": "2024-07-29T21:35:10.850058Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/wmt/raw/train/en-de.csv')\n",
    "val_data = pd.read_csv('/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/wmt/raw/valid/en-de.csv')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:35:11.717598Z",
     "start_time": "2024-07-29T21:35:11.710617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = train_data[['source','reference']]\n",
    "val_data = val_data[['source','reference']]"
   ],
   "id": "2a46e602caea365b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:35:12.425949Z",
     "start_time": "2024-07-29T21:35:12.422434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = train_data.rename(columns={'source':'source_text','reference':'target_text'})\n",
    "val_data = val_data.rename(columns={'source':'source_text','reference':'target_text'})"
   ],
   "id": "67cd050684c7961",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:35:12.789822Z",
     "start_time": "2024-07-29T21:35:12.786437Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.dropna(inplace=True)",
   "id": "f841d1caeafba3c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:35:13.751130Z",
     "start_time": "2024-07-29T21:35:13.460905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset\n",
    "})\n",
    "print(dataset)"
   ],
   "id": "bb5be2bbef77c93e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['source_text', 'target_text'],\n",
      "        num_rows: 17805\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['source_text', 'target_text'],\n",
      "        num_rows: 2569\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "29b8c10e00a6f61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:36:37.917667Z",
     "start_time": "2024-07-29T21:36:30.710633Z"
    }
   },
   "source": [
    "from transformers import MarianTokenizer\n",
    "model_token = 'Helsinki-NLP/opus-mt-en-de'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_token,return_tensors = 'pt')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43af394f649747a9b422bcdfc1857b37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5732e02d89414b9982f6595c76972a46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a77331d0c9c46028cac915a200c4fc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce1d4074507849f1890e41d10840b92f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b1d02e5fe8f43aba0bf1ff873ed3ae4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "        encodings = tokenizer('hi bub', max_length = 128,\n",
    "                                         truncation=True, padding=True,\n",
    "                                         return_tensors = 'pt')\n",
    "        \n",
    "encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T21:36:39.827652Z",
     "start_time": "2024-07-29T21:36:39.820602Z"
    }
   },
   "id": "95524c300c0add59",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4144: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  17, 2605,  700, 2606,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer(text_target='hi bub', max_length = 128,\n",
    "                                         truncation=True, padding=True,\n",
    "                                         return_tensors = 'pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T21:36:40.404360Z",
     "start_time": "2024-07-29T21:36:40.401370Z"
    }
   },
   "id": "1dd4f1816ae0cff0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  17, 2605,  700, 2606,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:36:43.741565Z",
     "start_time": "2024-07-29T21:36:43.737419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length=128\n",
    "\n",
    "def preprocess_function(example):\n",
    "        # print(example)\n",
    "        try:\n",
    "            inputs = example['source_text']\n",
    "            targets = example['target_text']\n",
    "            \n",
    "            if not isinstance(inputs,(str,list)):\n",
    "                inputs = str(inputs)\n",
    "            if not isinstance(targets,(str,list)):\n",
    "                targets = str(targets)\n",
    "            \n",
    "            input_encodings = tokenizer(inputs, max_length = max_length,\n",
    "                                             truncation=True, padding=True,\n",
    "                                             return_tensors = 'pt')#.to(device)\n",
    "            \n",
    "            target_encodings= tokenizer(max_length = max_length,\n",
    "                                             truncation=True, padding=True,\n",
    "                                             return_tensors = 'pt', text_target=targets)#.to(device)\n",
    "            \n",
    "            return {\n",
    "                'input_ids' : input_encodings['input_ids'],\n",
    "                'attention_mask' : input_encodings['attention_mask'],\n",
    "                'labels': target_encodings['input_ids']       \n",
    "            }\n",
    "        except Exception as e:\n",
    "            print('---------------------------------')\n",
    "            print(e)\n",
    "            print(example)\n",
    "            print(type(example['source_text']), type(example['target_text']))\n",
    "            \n",
    "            "
   ],
   "id": "5debc553a9316f96",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:36:53.674022Z",
     "start_time": "2024-07-29T21:36:52.148636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "train_data = dataset['train'].map(preprocess_function, batched=True)\n",
    "train_data.save_to_disk('./en_de_train_data')\n"
   ],
   "id": "9f666bd6f58e66f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/17805 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c7d596870594217b16fe67feb8bc32e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/17805 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d99c8079fe44f3098f6fce037f227ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:38:02.334148Z",
     "start_time": "2024-07-29T21:38:00.891948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "model_de_en = AutoModelForSeq2SeqLM.from_pretrained(model_token)"
   ],
   "id": "dda9ef441d8e9329",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer,model = model_fr_en)\n",
    "train_data = load_from_disk('./en_de_train_data')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T21:38:04.304674Z",
     "start_time": "2024-07-29T21:38:04.299184Z"
    }
   },
   "id": "e637974144900d82",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T21:38:04.671496Z",
     "start_time": "2024-07-29T21:38:04.669983Z"
    }
   },
   "id": "50cb22bb6610af3b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:38:05.690754Z",
     "start_time": "2024-07-29T21:38:05.688380Z"
    }
   },
   "cell_type": "code",
   "source": "model = model_de_en",
   "id": "5761bb813619b859",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_args = TrainingArguments(\n",
    "            output_dir='.output',\n",
    "            save_strategy='epoch',\n",
    "            num_train_epochs = 5,\n",
    "            learning_rate = 0.00002,\n",
    "            per_device_train_batch_size = 32,\n",
    "            per_device_eval_batch_size= 32,\n",
    "            weight_decay= 0.02,\n",
    "            save_total_limit = 3\n",
    "        )\n",
    "        \n",
    "trainer = Trainer(\n",
    "            model = model_de_en, args = trainer_args,\n",
    "            tokenizer = tokenizer, data_collator = seq2seq_data_collator,\n",
    "            train_dataset = train_data,      \n",
    "        )\n",
    "for param in model.model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze the decoder layers and the final linear layer\n",
    "for param in model.model.decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T22:19:55.808420Z",
     "start_time": "2024-07-29T21:38:09.751823Z"
    }
   },
   "id": "ef267a51b3a54660",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2785' max='2785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2785/2785 41:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2785, training_loss=0.1922291055401951, metrics={'train_runtime': 2505.6392, 'train_samples_per_second': 35.53, 'train_steps_per_second': 1.111, 'total_flos': 3016711098925056.0, 'train_loss': 0.1922291055401951, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:19:56.572429Z",
     "start_time": "2024-07-29T22:19:56.356867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.save_model(output_dir = './de_en_chat_model')\n",
    "tokenizer.save_pretrained('./de_en_chat_model')"
   ],
   "id": "1afd5558a3e2a4d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./de_en_chat_model/tokenizer_config.json',\n",
       " './de_en_chat_model/special_tokens_map.json',\n",
       " './de_en_chat_model/vocab.json',\n",
       " './de_en_chat_model/source.spm',\n",
       " './de_en_chat_model/target.spm',\n",
       " './de_en_chat_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:19:58.386698Z",
     "start_time": "2024-07-29T22:19:56.574512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('./de_en_chat_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./de_en_chat_model')"
   ],
   "id": "31b468f44f262741",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/.venv/lib/python3.12/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "loading configuration file ./de_en_chat_model/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"./de_en_chat_model\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.43.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading weights file ./de_en_chat_model/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 58100\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at ./de_en_chat_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file ./de_en_chat_model/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"renormalize_logits\": true\n",
      "}\n",
      "\n",
      "loading file source.spm\n",
      "loading file target.spm\n",
      "loading file vocab.json\n",
      "loading file target_vocab.json\n",
      "loading file tokenizer_config.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer.json\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:19:58.803753Z",
     "start_time": "2024-07-29T22:19:58.387500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    try:\n",
    "        inputs = example['source_text']\n",
    "        targets = example['target_text']\n",
    "        \n",
    "        if not isinstance(inputs,(str,list)):\n",
    "            inputs = str(inputs)\n",
    "        if not isinstance(targets,(str,list)):\n",
    "            targets = str(targets)\n",
    "                \n",
    "        return tokenizer(example['source_text'], padding='max_length', max_length=128, truncation=True)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "tokenized_dataset = dataset['val'].map(tokenize_function, batched=True)\n",
    "    \n",
    "\n",
    "input_ids = torch.tensor(tokenized_dataset['input_ids'])\n",
    "attention_mask = torch.tensor(tokenized_dataset['attention_mask'])\n"
   ],
   "id": "38726ccb44b161ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2569 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b02d054d7db4528b61f7337175b4059"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:33:49.352013Z",
     "start_time": "2024-07-29T22:19:58.804385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for input_id, attention_msk in zip(input_ids, attention_mask):\n",
    "        output = model.generate(input_ids=input_id.unsqueeze(0), attention_mask=attention_msk.unsqueeze(0))\n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        predictions.append(prediction)\n"
   ],
   "id": "76237ccd1efe50ea",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:33:49.361536Z",
     "start_time": "2024-07-29T22:33:49.353487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_texts = val_data['target_text'].tolist()\n",
    "len(val_texts)"
   ],
   "id": "78949c2fd0b54440",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2569"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:33:54.507910Z",
     "start_time": "2024-07-29T22:33:49.362280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "actual = val_texts\n",
    "predicted = predictions\n",
    "bleu = evaluate.load('bleu')\n",
    "bleu_score = bleu.compute(predictions = predicted,references = actual)\n",
    "print(f'BLEU Score: {bleu_score}')"
   ],
   "id": "523987cff129c67d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: {'bleu': 0.43360794586607154, 'precisions': [0.6796395771963265, 0.4762991706611885, 0.3675443762093043, 0.29711231951997], 'brevity_penalty': 1.0, 'length_ratio': 1.0234810059234563, 'translation_length': 28855, 'reference_length': 28193}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:33:57.617007Z",
     "start_time": "2024-07-29T22:33:54.508493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sacrebleu = evaluate.load('sacrebleu')\n",
    "sacrebleu_score = sacrebleu.compute(predictions = predicted,references = actual)\n",
    "print(f'SACREBLEU Score: {sacrebleu_score}')"
   ],
   "id": "958999cf619a4f4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SACREBLEU Score: {'score': 43.36079458660715, 'counts': [19611, 12520, 8738, 6338], 'totals': [28855, 26286, 23774, 21332], 'precisions': [67.96395771963265, 47.62991706611885, 36.754437620930425, 29.711231951997], 'bp': 1.0, 'sys_len': 28855, 'ref_len': 28193}\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
