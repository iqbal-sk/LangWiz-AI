{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T22:56:42.366764Z",
     "start_time": "2024-07-29T22:56:37.412991Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/europarl/processed/fr_en/fr_en.csv')\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         source_text  \\\n",
       "0                                                 4.   \n",
       "1  Ratification et mise en œuvre des conventions ...   \n",
       "2                                                 7.   \n",
       "3  Agriculture durable et biogaz: nécessité de re...   \n",
       "4              - Avant le vote sur le paragraphe 41:   \n",
       "\n",
       "                                         target_text  \n",
       "0                                                 4.  \n",
       "1  The ratification and implementation of the upd...  \n",
       "2                                                 7.  \n",
       "3  Sustainable agriculture and biogas: review of ...  \n",
       "4                 - Before the vote on paragraph 41:  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.</td>\n",
       "      <td>4.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ratification et mise en œuvre des conventions ...</td>\n",
       "      <td>The ratification and implementation of the upd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.</td>\n",
       "      <td>7.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agriculture durable et biogaz: nécessité de re...</td>\n",
       "      <td>Sustainable agriculture and biogas: review of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Avant le vote sur le paragraphe 41:</td>\n",
       "      <td>- Before the vote on paragraph 41:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:33.803107Z",
     "start_time": "2024-07-29T18:59:27.886819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def save_csv_percentage(input_file, output_file, percentage):\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    num_rows = len(df)\n",
    "    num_rows_to_save = int((percentage / 100) * num_rows)\n",
    "    \n",
    "    df_sampled = df.sample(n=num_rows_to_save, random_state=42)\n",
    "    \n",
    "    df_sampled.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Saved {num_rows_to_save} rows to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv_path = '/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/europarl/processed/fr_en/fr_en.csv'\n",
    "output_csv_path = '/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/europarl/processed/fr_en/fr_en_new.csv'\n",
    "percentage_to_save = 15.0 \n",
    "\n",
    "save_csv_percentage(input_csv_path, output_csv_path, percentage_to_save)"
   ],
   "id": "ab4b183a6352c352",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 285787 rows to /Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/europarl/processed/fr_en/fr_en_new.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:34.550413Z",
     "start_time": "2024-07-29T18:59:33.803909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/artifacts/data/europarl/processed/fr_en/fr_en_new.csv')\n",
    "data.head()"
   ],
   "id": "67cd050684c7961",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         source_text  \\\n",
       "0  Il est entendu que ce n'est pas une tâche des ...   \n",
       "1  Mais on doit savoir que le gel des prix agrico...   \n",
       "2  Les petites et moyennes entreprises (PME) voul...   \n",
       "3  Cela dit, au sujet des jeunes, nous devons nou...   \n",
       "4  Si ce rapport est approuvé - même renforcé par...   \n",
       "\n",
       "                                         target_text  \n",
       "0                 Granted, that is not exactly easy.  \n",
       "1  Nevertheless, we should recognize that the fre...  \n",
       "2  A greater degree of participation was sought b...  \n",
       "3  But when it comes to young people, we have to ...  \n",
       "4  If this report is approved - even supposing it...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Il est entendu que ce n'est pas une tâche des ...</td>\n",
       "      <td>Granted, that is not exactly easy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mais on doit savoir que le gel des prix agrico...</td>\n",
       "      <td>Nevertheless, we should recognize that the fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Les petites et moyennes entreprises (PME) voul...</td>\n",
       "      <td>A greater degree of participation was sought b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cela dit, au sujet des jeunes, nous devons nou...</td>\n",
       "      <td>But when it comes to young people, we have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si ce rapport est approuvé - même renforcé par...</td>\n",
       "      <td>If this report is approved - even supposing it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f3b7bfb77c62d346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:34.563963Z",
     "start_time": "2024-07-29T18:59:34.551541Z"
    }
   },
   "source": "train_data, val_data = train_test_split(data, test_size=0.2)\n",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:34.566119Z",
     "start_time": "2024-07-29T18:59:34.564669Z"
    }
   },
   "cell_type": "code",
   "source": "val_data = val_data[:2000]",
   "id": "a525b0a776e7d8b5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:35.044565Z",
     "start_time": "2024-07-29T18:59:34.566743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset\n",
    "})\n",
    "print(dataset)"
   ],
   "id": "bb5be2bbef77c93e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['source_text', 'target_text', '__index_level_0__'],\n",
      "        num_rows: 228629\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['source_text', 'target_text', '__index_level_0__'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "29b8c10e00a6f61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:36.647710Z",
     "start_time": "2024-07-29T18:59:35.046320Z"
    }
   },
   "source": [
    "from transformers import MarianTokenizer\n",
    "model_token = 'Helsinki-NLP/opus-mt-fr-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_token,return_tensors = 'pt')"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "        encodings = tokenizer('hi bub', max_length = 128,\n",
    "                                         truncation=True, padding=True,\n",
    "                                         return_tensors = 'pt')\n",
    "        \n",
    "encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:36.659037Z",
     "start_time": "2024-07-29T18:59:36.648279Z"
    }
   },
   "id": "95524c300c0add59",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4144: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[10648,   383,  2949,     0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer(text_target='hi bub', max_length = 128,\n",
    "                                         truncation=True, padding=True,\n",
    "                                         return_tensors = 'pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:36.661885Z",
     "start_time": "2024-07-29T18:59:36.659646Z"
    }
   },
   "id": "1dd4f1816ae0cff0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[10648,   383,  2949,     0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:59:36.665203Z",
     "start_time": "2024-07-29T18:59:36.663172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length=128\n",
    "\n",
    "def preprocess_function(example):\n",
    "        # print(example)\n",
    "        try:\n",
    "            inputs = example['source_text']\n",
    "            targets = example['target_text']\n",
    "            \n",
    "            if not isinstance(inputs,(str,list)):\n",
    "                inputs = str(inputs)\n",
    "            if not isinstance(targets,(str,list)):\n",
    "                targets = str(targets)\n",
    "            \n",
    "            input_encodings = tokenizer(inputs, max_length = max_length,\n",
    "                                             truncation=True, padding=True,\n",
    "                                             return_tensors = 'pt')#.to(device)\n",
    "            \n",
    "            target_encodings= tokenizer(max_length = max_length,\n",
    "                                             truncation=True, padding=True,\n",
    "                                             return_tensors = 'pt', text_target=targets)#.to(device)\n",
    "            \n",
    "            return {\n",
    "                'input_ids' : input_encodings['input_ids'],\n",
    "                'attention_mask' : input_encodings['attention_mask'],\n",
    "                'labels': target_encodings['input_ids']       \n",
    "            }\n",
    "        except Exception as e:\n",
    "            print('---------------------------------')\n",
    "            print(e)\n",
    "            print(example)\n",
    "            print(type(example['source_text']), type(example['target_text']))\n",
    "            \n",
    "            "
   ],
   "id": "5debc553a9316f96",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:00:07.950477Z",
     "start_time": "2024-07-29T18:59:36.665678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "train_data = dataset['train'].map(preprocess_function, batched=True)\n",
    "train_data.save_to_disk('./train_data')\n"
   ],
   "id": "9f666bd6f58e66f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/228629 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8cf3587427749a2ad90b40705520a18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/228629 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35f1f8c7ce1840c4bf996d8bb1fc7c73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:18:49.920927Z",
     "start_time": "2024-07-29T09:18:47.067671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "model_fr_en = AutoModelForSeq2SeqLM.from_pretrained(model_token)"
   ],
   "id": "dda9ef441d8e9329",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/vikkyfury/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/b4a9a384c2ec68a224bbd2ee3fd5df0c71ca5b1b/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.43.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/vikkyfury/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/b4a9a384c2ec68a224bbd2ee3fd5df0c71ca5b1b/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-fr-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /Users/vikkyfury/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/b4a9a384c2ec68a224bbd2ee3fd5df0c71ca5b1b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"renormalize_logits\": true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer,model = model_fr_en)\n",
    "train_data = load_from_disk('./train_data')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T09:18:53.648978Z",
     "start_time": "2024-07-29T09:18:53.603917Z"
    }
   },
   "id": "e637974144900d82",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-28T18:31:13.987137Z",
     "start_time": "2024-07-28T18:31:13.966388Z"
    }
   },
   "id": "50cb22bb6610af3b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T18:31:15.083778Z",
     "start_time": "2024-07-28T18:31:15.081402Z"
    }
   },
   "cell_type": "code",
   "source": "model = model_fr_en",
   "id": "5761bb813619b859",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_args = TrainingArguments(\n",
    "            output_dir='.output',\n",
    "            save_strategy='epoch',\n",
    "            num_train_epochs = 5,\n",
    "            learning_rate = 0.00002,\n",
    "            per_device_train_batch_size = 32,\n",
    "            per_device_eval_batch_size= 32,\n",
    "            weight_decay= 0.02,\n",
    "            save_total_limit = 3\n",
    "        )\n",
    "        \n",
    "trainer = Trainer(\n",
    "            model = model_fr_en, args = trainer_args,\n",
    "            tokenizer = tokenizer, data_collator = seq2seq_data_collator,\n",
    "            train_dataset = train_data,      \n",
    "        )\n",
    "for param in model.model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze the decoder layers and the final linear layer\n",
    "for param in model.model.decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T03:01:55.077060Z",
     "start_time": "2024-07-28T18:31:16.879130Z"
    }
   },
   "id": "ef267a51b3a54660",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35725' max='35725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35725/35725 8:30:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.323600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.285700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.275100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.270800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.270200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.266200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.259400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.260200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.256400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.257600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.250300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.252400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.251100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35725, training_loss=0.26561416294960144, metrics={'train_runtime': 30637.5988, 'train_samples_per_second': 37.312, 'train_steps_per_second': 1.166, 'total_flos': 3.875074637561856e+16, 'train_loss': 0.26561416294960144, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:01:55.446548Z",
     "start_time": "2024-07-29T03:01:55.177135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.save_model(output_dir = './fr_en_model')\n",
    "tokenizer.save_pretrained('./fr_en_model')"
   ],
   "id": "1afd5558a3e2a4d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fr_en_model/tokenizer_config.json',\n",
       " './fr_en_model/special_tokens_map.json',\n",
       " './fr_en_model/vocab.json',\n",
       " './fr_en_model/source.spm',\n",
       " './fr_en_model/target.spm',\n",
       " './fr_en_model/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:00:17.265588Z",
     "start_time": "2024-07-29T19:00:15.445062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('./fr_en_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./fr_en_model')"
   ],
   "id": "31b468f44f262741",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikkyfury/Desktop/pr/program/LangWiz-AI/.venv/lib/python3.12/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "loading configuration file ./fr_en_model/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"./fr_en_model\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.43.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading weights file ./fr_en_model/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at ./fr_en_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file ./fr_en_model/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"renormalize_logits\": true\n",
      "}\n",
      "\n",
      "loading file source.spm\n",
      "loading file target.spm\n",
      "loading file vocab.json\n",
      "loading file target_vocab.json\n",
      "loading file tokenizer_config.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer.json\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:00:19.795788Z",
     "start_time": "2024-07-29T19:00:19.359748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    try:\n",
    "        inputs = example['source_text']\n",
    "        targets = example['target_text']\n",
    "        \n",
    "        if not isinstance(inputs,(str,list)):\n",
    "            inputs = str(inputs)\n",
    "        if not isinstance(targets,(str,list)):\n",
    "            targets = str(targets)\n",
    "                \n",
    "        return tokenizer(example['source_text'], padding='max_length', max_length=128, truncation=True)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "tokenized_dataset = dataset['val'].map(tokenize_function, batched=True)\n",
    "    \n",
    "\n",
    "input_ids = torch.tensor(tokenized_dataset['input_ids'])\n",
    "attention_mask = torch.tensor(tokenized_dataset['attention_mask'])\n"
   ],
   "id": "38726ccb44b161ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "453da03b5420485d8eca069e1f61602d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:17:09.315482Z",
     "start_time": "2024-07-29T19:00:28.782506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for input_id, attention_msk in zip(input_ids, attention_mask):\n",
    "        output = model.generate(input_ids=input_id.unsqueeze(0), attention_mask=attention_msk.unsqueeze(0))\n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        predictions.append(prediction)\n"
   ],
   "id": "76237ccd1efe50ea",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:17:09.320407Z",
     "start_time": "2024-07-29T19:17:09.316805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_texts = val_data['target_text'].tolist()\n",
    "len(val_texts)"
   ],
   "id": "78949c2fd0b54440",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:45:05.128756Z",
     "start_time": "2024-07-29T19:45:00.864490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "actual = val_texts\n",
    "predicted = predictions\n",
    "bleu = evaluate.load('bleu')\n",
    "bleu_score = bleu.compute(predictions = predicted,references = actual)\n",
    "print(f'BLEU Score: {bleu_score}')"
   ],
   "id": "523987cff129c67d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: {'bleu': 0.42712631097499654, 'precisions': [0.7092186959450848, 0.4869144573987642, 0.36362743750368204, 0.2790403008256356], 'brevity_penalty': 0.9872274425545673, 'length_ratio': 0.9873083214985529, 'translation_length': 54921, 'reference_length': 55627}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:57:36.668282Z",
     "start_time": "2024-07-29T19:57:33.411773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sacrebleu = evaluate.load('sacrebleu')\n",
    "sacrebleu_score = sacrebleu.compute(predictions = predicted,references = actual)\n",
    "print(f'SACREBLEU Score: {sacrebleu_score}')"
   ],
   "id": "958999cf619a4f4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SACREBLEU Score: {'score': 42.712631097499646, 'counts': [38951, 25768, 18517, 13654], 'totals': [54921, 52921, 50923, 48932], 'precisions': [70.92186959450848, 48.69144573987642, 36.3627437503682, 27.90403008256356], 'bp': 0.9872274425545673, 'sys_len': 54921, 'ref_len': 55627}\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
